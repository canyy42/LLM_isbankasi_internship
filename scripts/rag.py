# scripts/rag.py

#!/usr/bin/env python3

"""
rag.py

AmaÃ§:
- RAG (Retrieval-Augmented Generation) iÅŸlevlerini saÄŸla
- Prompt oluÅŸtur
- Groq ChatCompletion ile yanÄ±t Ã¼ret
- FAISS ile vektÃ¶r arama yap
"""

import faiss
import numpy as np
from dotenv import load_dotenv
import os
from groq import Groq
import pandas as pd
from langdetect import detect
import pickle

print("RAG sistemi baÅŸlatÄ±lÄ±yor...")

load_dotenv()

api_key = os.getenv("API_KEY")
client = Groq(api_key=api_key)

# Load data
try:
    df = pd.read_csv("data/chunked_data.csv")
    chunked_data = df.to_dict(orient="records")
    
    # Load FAISS index if available
    if os.path.exists("data/faiss_index.index"):
        index = faiss.read_index("data/faiss_index.index")
        with open("data/faiss_metadata.pkl", "rb") as f:
            metadata = pickle.load(f)
    else:
        index = None
        metadata = None
        print("âš ï¸  FAISS index bulunamadÄ±, basit arama kullanÄ±lÄ±yor")
except Exception as e:
    print(f"âŒ Veri yÃ¼kleme hatasÄ±: {e}")
    chunked_data = []
    index = None
    metadata = None

def search_context(question, top_k=3):
    """Search for relevant context using FAISS or fallback to simple search"""
    if index is not None and metadata is not None:
        # Use FAISS for fast similarity search
        try:
            # For now, we'll use a simple approach
            # In a real implementation, you'd embed the question and search
            relevant_chunks = []
            question_lower = question.lower()
            
            for chunk in chunked_data[:10]:  # Search in first 10 chunks for demo
                if any(word in chunk.get('content', '').lower() for word in question_lower.split()):
                    relevant_chunks.append(chunk.get('content', '')[:500])
                    if len(relevant_chunks) >= top_k:
                        break
            
            return "\n\n".join(relevant_chunks) if relevant_chunks else "Finans ve bankacÄ±lÄ±k alanÄ±nda genel bilgiler."
        except Exception as e:
            print(f"FAISS search error: {e}")
    
    # Fallback to simple search
    relevant_chunks = []
    question_lower = question.lower()
    
    for chunk in chunked_data[:20]:
        if any(word in chunk.get('content', '').lower() for word in question_lower.split()):
            relevant_chunks.append(chunk.get('content', '')[:500])
            if len(relevant_chunks) >= top_k:
                break
    
    return "\n\n".join(relevant_chunks) if relevant_chunks else "Finans ve bankacÄ±lÄ±k alanÄ±nda genel bilgiler."

def generate_answer(question, conversation_history=None):
    """Generate answer using Groq API with RAG context"""
    try:
        context = search_context(question)
        
        # Detect language with character length check first
        try:
            if len(question) < 12:
                lang_text = "TÃ¼rkÃ§e"
            elif detect(question) == "tr":
                lang_text = "TÃ¼rkÃ§e"
            elif detect(question) == "en":
                lang_text = "Ä°ngilizce"
            else:
                lang_text = "TÃ¼rkÃ§e"
        except:
            lang_text = "TÃ¼rkÃ§e"
        
        # Generate conversation summary if history exists
        conversation_summary = ""
        if conversation_history and len(conversation_history) > 0:
            try:
                summary_prompt = f"""
AÅŸaÄŸÄ±daki konuÅŸma geÃ§miÅŸini kÄ±sa bir Ã¶zet haline getir. 
Sadece Ã¶nemli noktalarÄ± ve konu baÄŸlamÄ±nÄ± belirt:

{conversation_history}

Ã–zet:"""
                
                summary_response = client.chat.completions.create(
                    model="llama3-8b-8192",
                    messages=[
                        {"role": "system", "content": "Sen bir konuÅŸma Ã¶zetleyicisisin. Sadece Ã¶nemli noktalarÄ± kÄ±saca Ã¶zetle."},
                        {"role": "user", "content": summary_prompt}
                    ],
                    max_tokens=150
                )
                conversation_summary = summary_response.choices[0].message.content.strip()
            except Exception as e:
                print(f"Conversation summary error: {e}")
                conversation_summary = ""

        # Main prompt with context and conversation history
        prompt = f"""
Sen finans, bankacÄ±lÄ±k ve ekonomi alanlarÄ±nda uzmanlaÅŸmÄ±ÅŸ bir yapay zekÃ¢ danÄ±ÅŸmanÄ±sÄ±n.
AÅŸaÄŸÄ±da bir kullanÄ±cÄ±nÄ±n sorusu ve bu soruya dair bazÄ± bilgi parÃ§alarÄ± (baÄŸlam) yer alÄ±yor. 
GÃ¶revin, bu baÄŸlama dayanarak doÄŸru, aÃ§Ä±k ve tekrar etmeyen bir cevap Ã¼retmek.

â—ï¸ CevabÄ±nÄ± hazÄ±rlarken ÅŸu kurallara dikkat et:
- AynÄ± kelimeleri tekrar tekrar kullanma. AnlamÄ± koruyarak eÅŸ anlamlÄ±larla zenginleÅŸtir.
- Gereksiz tekrarlar, dÃ¶ngÃ¼sel anlatÄ±mlar ve soyut genellemelerden kaÃ§Ä±n.
- Uzunsa madde madde yaz.
- Elindeki bilgi yetersizse bunu dÃ¼rÃ¼stÃ§e belirt.
- Ãœst Ã¼ste aynÄ± kelimeleri kullanma.

### CEVAP DÄ°LÄ° ###
{lang_text}

### KONUÅMA GEÃ‡MÄ°ÅÄ° ###
{conversation_summary if conversation_summary else "Yeni konuÅŸma"}

### BAÄLAM ###
{context}

### SORU ###
{question}

### CEVAP ###
"""

        response = client.chat.completions.create(
            model="llama3-70b-8192",  # veya llama3-8b-8192
            messages=[
                {"role": "system", "content": "Sen bir finans asistanÄ±sÄ±n. SorularÄ± aÃ§Ä±k, anlaÅŸÄ±lÄ±r ve baÄŸlama dayalÄ± olarak cevapla."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000
        )
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        return f"[!] YanÄ±t Ã¼retme hatasÄ±: {e}"

def main():
    """
    BankacÄ±lÄ±k asistanÄ± iÃ§in interaktif komut satÄ±rÄ± uygulamasÄ±.
    Her soruyu ayrÄ± iÅŸlem olarak iÅŸler, geÃ§miÅŸi hatÄ±rlamaz.
    """
    print("ğŸ¦ Finans AsistanÄ± RAG Sistemi")
    print("=" * 40)
    
    while True:
        question = input("\nğŸ’¬ Soru (Ã§Ä±kmak iÃ§in 'q'): ").strip()
        if question.lower() in ["q", "-quit", "Ã§Ä±k", "exit", "dur", "du", "d"]:
            print("ğŸ”š Ã‡Ä±kÄ±lÄ±yor...")
            break
        
        if not question:
            continue
            
        print("ğŸ” BaÄŸlam aranÄ±yor...")
        answer = generate_answer(question)
        print("\nğŸ“Œ YanÄ±t:")
        print(answer)
        print("-" * 50)

if __name__ == "__main__":
    main()
